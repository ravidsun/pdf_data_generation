[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "vedic-astro-data-gen"
version = "1.0.0"
description = "Comprehensive data generation pipeline for Vedic Astrology (Jyotish) LLM fine-tuning"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.10"
authors = [
    {name = "Vedic Astrology ML Project", email = "project@example.com"}
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]
dependencies = [
    # PDF Processing
    "pymupdf>=1.24.0",
    "pdfplumber>=0.10.0",
    
    # LangChain for document processing
    "langchain>=0.2.0",
    "langchain-core>=0.2.0",
    "langchain-community>=0.2.0",
    "langchain-text-splitters>=0.2.0",
    
    # Data processing
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    
    # NLP utilities
    "sentence-transformers>=2.2.0",
    "scikit-learn>=1.3.0",
    "rapidfuzz>=3.0.0",
    
    # CLI and utilities
    "typer[all]>=0.9.0",
    "rich>=13.0.0",
    "pyyaml>=6.0",
    "python-dotenv>=1.0.0",
    
    # Progress bars
    "tqdm>=4.65.0",
]

[project.optional-dependencies]
# For LLM-based QA generation - Proprietary APIs
llm = [
    "langchain-anthropic>=0.1.0",
    "anthropic>=0.25.0",
    "langchain-openai>=0.1.0",
    "openai>=1.0.0",
]
# For Open Source LLMs (Local and API)
llm-opensource = [
    "langchain-huggingface>=0.0.1",
    "transformers>=4.35.0",
    "torch>=2.0.0",
    "accelerate>=0.24.0",
    "bitsandbytes>=0.41.0",  # For quantization
    "sentencepiece>=0.1.99",  # For tokenization
    "langchain-ollama>=0.1.0",  # For Ollama integration
    "requests>=2.31.0",  # For API calls
]
# For vLLM (high-performance inference)
llm-vllm = [
    "vllm>=0.2.0",
    "langchain-community>=0.2.0",
]
# All LLM options
llm-all = [
    "langchain-anthropic>=0.1.0",
    "anthropic>=0.25.0",
    "langchain-openai>=0.1.0",
    "openai>=1.0.0",
    "langchain-huggingface>=0.0.1",
    "transformers>=4.35.0",
    "torch>=2.0.0",
    "accelerate>=0.24.0",
    "bitsandbytes>=0.41.0",
    "sentencepiece>=0.1.99",
    "langchain-ollama>=0.1.0",
    "requests>=2.31.0",
]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
]

[project.scripts]
vedic-gen = "vedic_astro_gen.cli:app"

[project.urls]
Homepage = "https://github.com/example/vedic-astro-data-gen"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
vedic_astro_gen = ["*.yaml", "*.json"]

[tool.black]
line-length = 100
target-version = ["py310"]

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "N", "W"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
